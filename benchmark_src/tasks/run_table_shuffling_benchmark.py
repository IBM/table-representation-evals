import json
import logging
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, List, Tuple

import numpy as np
import pandas as pd
from hydra.utils import get_original_cwd
from omegaconf import DictConfig

from benchmark_src.approach_interfaces.table_embedding_interface import (
    TableEmbeddingInterface,
)
from benchmark_src.dataset_creation.table_structure_datasets.generate_triplet_datasets import (
    load_table_shuffling_config,
    run_variation_by_name,
)
from benchmark_src.utils import result_utils
from benchmark_src.utils.framework import get_approach_class
from benchmark_src.utils.resource_monitoring import (
    monitor_resources,
    save_resource_metrics_to_disk,
)
from benchmark_src.tasks import component_utils

logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)


@dataclass
class TripletCase:
    triplet_id: int
    anchor_table: List[List[Any]]
    pos_table: List[List[Any]]
    neg_table: List[List[Any]]
    delta_pos: float
    delta_neg: float


def resolve_dataset_and_variation(encoded_dataset_name: str) -> Tuple[str, str]:
    """
    Parse cfg.dataset_name for the table_shuffling task.

    Expected format: "<dataset_id>@@<variation_id>", e.g. "fetaqa@@v0".
    """
    cfg = load_table_shuffling_config()

    datasets_cfg = cfg["datasets"]
    variations_cfg = cfg["variations"]

    if "@@" not in encoded_dataset_name:
        raise ValueError(
            f"Invalid table_shuffling dataset name '{encoded_dataset_name}'. "
            "Expected format '<dataset_id>@@<variation_id>', e.g. 'fetaqa@@v0'."
        )

    dataset_id, variation_id = encoded_dataset_name.split("@@", 1)

    if dataset_id not in datasets_cfg:
        available = ", ".join(sorted(datasets_cfg.keys()))
        raise ValueError(
            f"Unknown table_shuffling dataset_id '{dataset_id}' parsed from '{encoded_dataset_name}'. "
            f"Available datasets: {available}"
        )

    if variation_id not in variations_cfg:
        available = ", ".join(sorted(variations_cfg.keys()))
        raise ValueError(
            f"Unknown table_shuffling variation_id '{variation_id}' parsed from '{encoded_dataset_name}'. "
            f"Available variations: {available}"
        )

    return dataset_id, variation_id


def _df_to_table(df: pd.DataFrame) -> List[List[Any]]:
    """
    Convert a DataFrame back into the list-of-lists table format expected by
    TableEmbeddingInterface, with the first row as header.
    """
    if df is None or df.empty:
        return []

    header = list(df.columns)
    rows: List[List[Any]] = []

    for _, row in df.iterrows():
        # Convert values to strings (or empty string) to avoid type issues
        converted = []
        for val in row.tolist():
            if pd.isna(val):
                converted.append("")
            else:
                converted.append(str(val))
        rows.append(converted)

    return [header] + rows


def load_triplets_for_dataset_variation(dataset_id: str, variation_id: str) -> List[TripletCase]:
    """
    Load triplets for a given (dataset, variation) pair from the cache generated by generate_triplet_datasets.py
    """
    try:
        project_root = Path(get_original_cwd())
    except ValueError:
        project_root = Path.cwd()

    variation_dir = project_root / "cache" / "table_shuffling" / dataset_id / variation_id

    if not variation_dir.exists():
        logger.info(
            f"Expected variation directory not found at {variation_dir}. "
            f"Attempting to generate triplets for dataset='{dataset_id}', variation='{variation_id}' now."
        )
        try:
            run_variation_by_name(dataset_id, variation_id)
        except ValueError as e:
            raise FileNotFoundError(
                f"Expected variation directory not found at {variation_dir} "
                "is not defined in table_shuffling.yaml."
            ) from e

        if not variation_dir.exists():
            raise FileNotFoundError(
                f"Failed to generate variation directory at {variation_dir} "
                f"for dataset='{dataset_id}', variation='{variation_id}'."
            )

    summary_path = variation_dir / "triplet_generation_summary.jsonl"
    if not summary_path.exists():
        raise FileNotFoundError(
            f"Expected triplet summary file not found at {summary_path}. "
            "Please run the table shuffling triplet generation script first."
        )

    with open(summary_path, "r", encoding="utf-8") as f:
        summary = json.load(f)

    triplets_raw = summary.get("triplets", [])
    if not triplets_raw:
        logger.error(f"No triplets found in summary file for dataset {dataset_id} and variation {variation_id}.")
        return []

    triplets: List[TripletCase] = []

    for t in triplets_raw:
        triplet_id = t["triplet_id"]

        anchor_csv = variation_dir / f"{triplet_id}_anchor.csv"
        pos_csv = variation_dir / f"{triplet_id}_pos.csv"
        neg_csv = variation_dir / f"{triplet_id}_neg.csv"

        for path in (anchor_csv, pos_csv, neg_csv):
            if not path.exists():
                raise FileNotFoundError(f"Missing CSV file for triplet {triplet_id} in dataset {dataset_id} and variation {variation_id}: {path}")

        anchor_df = pd.read_csv(anchor_csv)
        pos_df = pd.read_csv(pos_csv)
        neg_df = pd.read_csv(neg_csv)

        anchor_table = _df_to_table(anchor_df)
        pos_table = _df_to_table(pos_df)
        neg_table = _df_to_table(neg_df)

        triplets.append(
            TripletCase(
                triplet_id=int(triplet_id),
                anchor_table=anchor_table,
                pos_table=pos_table,
                neg_table=neg_table,
                delta_pos=float(t["delta_pos"]),
                delta_neg=float(t["delta_neg"]),
            )
        )

    logger.info(f"Loaded {len(triplets)} triplets for dataset {dataset_id} and variation {variation_id} from {variation_dir}")
    return triplets


def _cosine_distance(
    a: np.ndarray, b: np.ndarray, eps: float = 1e-8
) -> float:
    a = np.asarray(a, dtype=float).ravel()
    b = np.asarray(b, dtype=float).ravel()

    if a.size == 0 or b.size == 0:
        return 1.0

    denom = (np.linalg.norm(a) * np.linalg.norm(b)) + eps
    if denom <= 0:
        return 1.0

    sim = float(np.dot(a, b) / denom)
    return 1.0 - sim


def _pearson_correlation(x: List[float], y: List[float]) -> float:
    if len(x) < 2 or len(y) < 2:
        return 0.0

    x_arr = np.asarray(x, dtype=float)
    y_arr = np.asarray(y, dtype=float)

    if np.allclose(x_arr, x_arr[0]) or np.allclose(y_arr, y_arr[0]):
        return 0.0

    try:
        corr_matrix = np.corrcoef(x_arr, y_arr)
        corr = float(corr_matrix[0, 1])
    except Exception:
        corr = 0.0

    if np.isnan(corr):
        return 0.0
    return corr


def get_embedder(cfg: DictConfig) -> Tuple[TableEmbeddingInterface, Dict[str, Any]]:
    approach_cls = get_approach_class(cfg)
    embedder = approach_cls(cfg)
    table_component: TableEmbeddingInterface = embedder._load_component(
        "table_embedding_component", "TableEmbeddingComponent", TableEmbeddingInterface
    )
    _, resource_metrics_setup = component_utils.run_model_setup(
        component=table_component
    )
    return table_component, resource_metrics_setup


@monitor_resources()
def run_benchmark(
    cfg: DictConfig,
    table_embedding_component: TableEmbeddingInterface,
    triplets: List[TripletCase],
    variation_name: str,
) -> Dict[str, Any]:
    """
    Core evaluation loop for the table shuffling task.

    For each triplet (anchor, pos, neg), we compute:
      - Triplet Accuracy: fraction of triplets where d(anchor, pos) < d(anchor, neg)
      - Triplet Silhouette Score: mean of (d_neg - d_pos) / max(d_pos, d_neg) in [-1, 1]
      - Bounded Contrastive Score: mean of d_pos / (d_pos + d_neg) in [0, 1]
      - Textual Bias: Pearson correlation between embedding distance d(anchor, pos)
        and the textual distance delta_pos (normalized Levenshtein from dataset).
    """
    eps = 1e-8
    correct_flags: List[bool] = []
    silhouette_scores: List[float] = []
    contrastive_scores: List[float] = []
    pos_embedding_distances: List[float] = []
    delta_pos_values: List[float] = []
    d_pos_list: List[float] = []
    d_neg_list: List[float] = []

    detailed_results: List[Dict[str, Any]] = []

    total_triplets = len(triplets)
    correct_count = 0

    for i, t in enumerate(triplets):
        emb_anchor = np.asarray(
            table_embedding_component.create_table_embedding(t.anchor_table),
            dtype=float,
        )
        emb_pos = np.asarray(
            table_embedding_component.create_table_embedding(t.pos_table),
            dtype=float,
        )
        emb_neg = np.asarray(
            table_embedding_component.create_table_embedding(t.neg_table),
            dtype=float,
        )

        d_pos = _cosine_distance(emb_anchor, emb_pos, eps=eps)
        d_neg = _cosine_distance(emb_anchor, emb_neg, eps=eps)

        d_pos_list.append(d_pos)
        d_neg_list.append(d_neg)

        is_correct = d_pos < d_neg
        correct_flags.append(is_correct)
        if is_correct:
            correct_count += 1

        if (i + 1) % 10 == 0:
            logger.info(
                f"Table shuffling progress: {i + 1}/{total_triplets} | correct={correct_count}"
            )

        # Triplet Silhouette: (d_neg - d_pos) / max(d_pos, d_neg), range [-1, 1]
        denom_sil = max(d_pos, d_neg) + eps
        silhouette = (d_neg - d_pos) / denom_sil
        silhouette_scores.append(silhouette)

        # Bounded Contrastive: d_pos / (d_pos + d_neg), range [0, 1]
        denom_contr = d_pos + d_neg + eps
        contrastive = d_pos / denom_contr
        contrastive_scores.append(contrastive)

        pos_embedding_distances.append(d_pos)
        delta_pos_values.append(t.delta_pos)

        detailed_results.append(
            {
                "triplet_id": t.triplet_id,
                "d_pos": d_pos,
                "d_neg": d_neg,
                "silhouette": silhouette,
                "contrastive": contrastive,
                "delta_pos": t.delta_pos,
                "delta_neg": t.delta_neg,
            }
        )

    triplet_accuracy = float(np.mean(correct_flags)) if correct_flags else 0.0
    mean_silhouette = float(np.mean(silhouette_scores)) if silhouette_scores else 0.0
    mean_contrastive = float(np.mean(contrastive_scores)) if contrastive_scores else 0.5
    textual_bias = _pearson_correlation(pos_embedding_distances, delta_pos_values)

    metrics = {
        "TripletAccuracy": triplet_accuracy,
        "Triplet Silhouette Score": mean_silhouette,
        "Bounded Contrastive Score": mean_contrastive,
        "TextualBias_pearson": textual_bias,
        "mean_d_pos": float(np.mean(d_pos_list)),
        "mean_d_neg": float(np.mean(d_neg_list)),
    }

    # Save a detailed per-triplet dump for analysis
    try:
        with open("full_results.json", "w", encoding="utf-8") as f:
            json.dump(
                {
                    "dataset_name": cfg.dataset_name,
                    "variation_name": variation_name,
                    "triplets": detailed_results,
                    "metrics": metrics,
                },
                f,
                indent=2,
            )
        logger.info("Saved full per-triplet results to 'full_results.json'")
    except Exception as e:
        logger.error(f"Failed to save full_results.json: {e}")

    return metrics


def main(cfg: DictConfig) -> None:
    logger.debug("Started run_table_shuffling_benchmark.main")
    logger.debug("Received cfg:")
    logger.debug(cfg)
    logger.info(f"Running table shuffling benchmark for dataset/variation '{cfg.dataset_name}'")

    dataset_id, variation_id = resolve_dataset_and_variation(cfg.dataset_name)
    triplets = load_triplets_for_dataset_variation(dataset_id, variation_id)

    if not triplets:
        logger.error(f"No triplets to evaluate for dataset='{dataset_id}', variation='{variation_id}'. Skipping evaluation with no outputs.")
        return

    table_embedding_component, resource_metrics_setup = get_embedder(cfg)

    metrics, resource_metrics_task = run_benchmark(
        cfg=cfg,
        table_embedding_component=table_embedding_component,
        triplets=triplets,
        variation_name=cfg.dataset_name,
    )

    if resource_metrics_setup:
        save_resource_metrics_to_disk(
            cfg=cfg,
            resource_metrics_setup=resource_metrics_setup,
            resource_metrics_task=resource_metrics_task,
        )

    result_utils.save_results(cfg=cfg, metrics=metrics)
